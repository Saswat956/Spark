{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4SMHqrql8OB"
      },
      "source": [
        "# Creating Spark Session\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqaFEAPUUIWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d850c9-346c-42e3-def3-df1436084f81"
      },
      "source": [
        "#import findspark\n",
        "#findspark.init()\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=12b5094b18c8a65da1f13ffb4d4924c384c89114a1563deca47e7c2cdda7531b\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QfqBA1XmR1K"
      },
      "source": [
        "# **Creating a Spark Context**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVfR_YipUjf1"
      },
      "source": [
        "sc=spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to calculate mod**"
      ],
      "metadata": {
        "id": "DeSo3cbMXwLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mod(x):\n",
        "    import numpy as np\n",
        "    return (x, np.mod(x, 2))"
      ],
      "metadata": {
        "id": "WKHuDBacXyHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaKscOUCnKfX"
      },
      "source": [
        "**Creating an RDD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojCk6ki8mthn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefd8904-f733-419a-b857-ea80f93fa3ab"
      },
      "source": [
        "rdd = sc.parallelize(range(1000)).map(mod).collect()\n",
        "print(rdd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0), (1, 1), (2, 0), (3, 1), (4, 0), (5, 1), (6, 0), (7, 1), (8, 0), (9, 1), (10, 0), (11, 1), (12, 0), (13, 1), (14, 0), (15, 1), (16, 0), (17, 1), (18, 0), (19, 1), (20, 0), (21, 1), (22, 0), (23, 1), (24, 0), (25, 1), (26, 0), (27, 1), (28, 0), (29, 1), (30, 0), (31, 1), (32, 0), (33, 1), (34, 0), (35, 1), (36, 0), (37, 1), (38, 0), (39, 1), (40, 0), (41, 1), (42, 0), (43, 1), (44, 0), (45, 1), (46, 0), (47, 1), (48, 0), (49, 1), (50, 0), (51, 1), (52, 0), (53, 1), (54, 0), (55, 1), (56, 0), (57, 1), (58, 0), (59, 1), (60, 0), (61, 1), (62, 0), (63, 1), (64, 0), (65, 1), (66, 0), (67, 1), (68, 0), (69, 1), (70, 0), (71, 1), (72, 0), (73, 1), (74, 0), (75, 1), (76, 0), (77, 1), (78, 0), (79, 1), (80, 0), (81, 1), (82, 0), (83, 1), (84, 0), (85, 1), (86, 0), (87, 1), (88, 0), (89, 1), (90, 0), (91, 1), (92, 0), (93, 1), (94, 0), (95, 1), (96, 0), (97, 1), (98, 0), (99, 1), (100, 0), (101, 1), (102, 0), (103, 1), (104, 0), (105, 1), (106, 0), (107, 1), (108, 0), (109, 1), (110, 0), (111, 1), (112, 0), (113, 1), (114, 0), (115, 1), (116, 0), (117, 1), (118, 0), (119, 1), (120, 0), (121, 1), (122, 0), (123, 1), (124, 0), (125, 1), (126, 0), (127, 1), (128, 0), (129, 1), (130, 0), (131, 1), (132, 0), (133, 1), (134, 0), (135, 1), (136, 0), (137, 1), (138, 0), (139, 1), (140, 0), (141, 1), (142, 0), (143, 1), (144, 0), (145, 1), (146, 0), (147, 1), (148, 0), (149, 1), (150, 0), (151, 1), (152, 0), (153, 1), (154, 0), (155, 1), (156, 0), (157, 1), (158, 0), (159, 1), (160, 0), (161, 1), (162, 0), (163, 1), (164, 0), (165, 1), (166, 0), (167, 1), (168, 0), (169, 1), (170, 0), (171, 1), (172, 0), (173, 1), (174, 0), (175, 1), (176, 0), (177, 1), (178, 0), (179, 1), (180, 0), (181, 1), (182, 0), (183, 1), (184, 0), (185, 1), (186, 0), (187, 1), (188, 0), (189, 1), (190, 0), (191, 1), (192, 0), (193, 1), (194, 0), (195, 1), (196, 0), (197, 1), (198, 0), (199, 1), (200, 0), (201, 1), (202, 0), (203, 1), (204, 0), (205, 1), (206, 0), (207, 1), (208, 0), (209, 1), (210, 0), (211, 1), (212, 0), (213, 1), (214, 0), (215, 1), (216, 0), (217, 1), (218, 0), (219, 1), (220, 0), (221, 1), (222, 0), (223, 1), (224, 0), (225, 1), (226, 0), (227, 1), (228, 0), (229, 1), (230, 0), (231, 1), (232, 0), (233, 1), (234, 0), (235, 1), (236, 0), (237, 1), (238, 0), (239, 1), (240, 0), (241, 1), (242, 0), (243, 1), (244, 0), (245, 1), (246, 0), (247, 1), (248, 0), (249, 1), (250, 0), (251, 1), (252, 0), (253, 1), (254, 0), (255, 1), (256, 0), (257, 1), (258, 0), (259, 1), (260, 0), (261, 1), (262, 0), (263, 1), (264, 0), (265, 1), (266, 0), (267, 1), (268, 0), (269, 1), (270, 0), (271, 1), (272, 0), (273, 1), (274, 0), (275, 1), (276, 0), (277, 1), (278, 0), (279, 1), (280, 0), (281, 1), (282, 0), (283, 1), (284, 0), (285, 1), (286, 0), (287, 1), (288, 0), (289, 1), (290, 0), (291, 1), (292, 0), (293, 1), (294, 0), (295, 1), (296, 0), (297, 1), (298, 0), (299, 1), (300, 0), (301, 1), (302, 0), (303, 1), (304, 0), (305, 1), (306, 0), (307, 1), (308, 0), (309, 1), (310, 0), (311, 1), (312, 0), (313, 1), (314, 0), (315, 1), (316, 0), (317, 1), (318, 0), (319, 1), (320, 0), (321, 1), (322, 0), (323, 1), (324, 0), (325, 1), (326, 0), (327, 1), (328, 0), (329, 1), (330, 0), (331, 1), (332, 0), (333, 1), (334, 0), (335, 1), (336, 0), (337, 1), (338, 0), (339, 1), (340, 0), (341, 1), (342, 0), (343, 1), (344, 0), (345, 1), (346, 0), (347, 1), (348, 0), (349, 1), (350, 0), (351, 1), (352, 0), (353, 1), (354, 0), (355, 1), (356, 0), (357, 1), (358, 0), (359, 1), (360, 0), (361, 1), (362, 0), (363, 1), (364, 0), (365, 1), (366, 0), (367, 1), (368, 0), (369, 1), (370, 0), (371, 1), (372, 0), (373, 1), (374, 0), (375, 1), (376, 0), (377, 1), (378, 0), (379, 1), (380, 0), (381, 1), (382, 0), (383, 1), (384, 0), (385, 1), (386, 0), (387, 1), (388, 0), (389, 1), (390, 0), (391, 1), (392, 0), (393, 1), (394, 0), (395, 1), (396, 0), (397, 1), (398, 0), (399, 1), (400, 0), (401, 1), (402, 0), (403, 1), (404, 0), (405, 1), (406, 0), (407, 1), (408, 0), (409, 1), (410, 0), (411, 1), (412, 0), (413, 1), (414, 0), (415, 1), (416, 0), (417, 1), (418, 0), (419, 1), (420, 0), (421, 1), (422, 0), (423, 1), (424, 0), (425, 1), (426, 0), (427, 1), (428, 0), (429, 1), (430, 0), (431, 1), (432, 0), (433, 1), (434, 0), (435, 1), (436, 0), (437, 1), (438, 0), (439, 1), (440, 0), (441, 1), (442, 0), (443, 1), (444, 0), (445, 1), (446, 0), (447, 1), (448, 0), (449, 1), (450, 0), (451, 1), (452, 0), (453, 1), (454, 0), (455, 1), (456, 0), (457, 1), (458, 0), (459, 1), (460, 0), (461, 1), (462, 0), (463, 1), (464, 0), (465, 1), (466, 0), (467, 1), (468, 0), (469, 1), (470, 0), (471, 1), (472, 0), (473, 1), (474, 0), (475, 1), (476, 0), (477, 1), (478, 0), (479, 1), (480, 0), (481, 1), (482, 0), (483, 1), (484, 0), (485, 1), (486, 0), (487, 1), (488, 0), (489, 1), (490, 0), (491, 1), (492, 0), (493, 1), (494, 0), (495, 1), (496, 0), (497, 1), (498, 0), (499, 1), (500, 0), (501, 1), (502, 0), (503, 1), (504, 0), (505, 1), (506, 0), (507, 1), (508, 0), (509, 1), (510, 0), (511, 1), (512, 0), (513, 1), (514, 0), (515, 1), (516, 0), (517, 1), (518, 0), (519, 1), (520, 0), (521, 1), (522, 0), (523, 1), (524, 0), (525, 1), (526, 0), (527, 1), (528, 0), (529, 1), (530, 0), (531, 1), (532, 0), (533, 1), (534, 0), (535, 1), (536, 0), (537, 1), (538, 0), (539, 1), (540, 0), (541, 1), (542, 0), (543, 1), (544, 0), (545, 1), (546, 0), (547, 1), (548, 0), (549, 1), (550, 0), (551, 1), (552, 0), (553, 1), (554, 0), (555, 1), (556, 0), (557, 1), (558, 0), (559, 1), (560, 0), (561, 1), (562, 0), (563, 1), (564, 0), (565, 1), (566, 0), (567, 1), (568, 0), (569, 1), (570, 0), (571, 1), (572, 0), (573, 1), (574, 0), (575, 1), (576, 0), (577, 1), (578, 0), (579, 1), (580, 0), (581, 1), (582, 0), (583, 1), (584, 0), (585, 1), (586, 0), (587, 1), (588, 0), (589, 1), (590, 0), (591, 1), (592, 0), (593, 1), (594, 0), (595, 1), (596, 0), (597, 1), (598, 0), (599, 1), (600, 0), (601, 1), (602, 0), (603, 1), (604, 0), (605, 1), (606, 0), (607, 1), (608, 0), (609, 1), (610, 0), (611, 1), (612, 0), (613, 1), (614, 0), (615, 1), (616, 0), (617, 1), (618, 0), (619, 1), (620, 0), (621, 1), (622, 0), (623, 1), (624, 0), (625, 1), (626, 0), (627, 1), (628, 0), (629, 1), (630, 0), (631, 1), (632, 0), (633, 1), (634, 0), (635, 1), (636, 0), (637, 1), (638, 0), (639, 1), (640, 0), (641, 1), (642, 0), (643, 1), (644, 0), (645, 1), (646, 0), (647, 1), (648, 0), (649, 1), (650, 0), (651, 1), (652, 0), (653, 1), (654, 0), (655, 1), (656, 0), (657, 1), (658, 0), (659, 1), (660, 0), (661, 1), (662, 0), (663, 1), (664, 0), (665, 1), (666, 0), (667, 1), (668, 0), (669, 1), (670, 0), (671, 1), (672, 0), (673, 1), (674, 0), (675, 1), (676, 0), (677, 1), (678, 0), (679, 1), (680, 0), (681, 1), (682, 0), (683, 1), (684, 0), (685, 1), (686, 0), (687, 1), (688, 0), (689, 1), (690, 0), (691, 1), (692, 0), (693, 1), (694, 0), (695, 1), (696, 0), (697, 1), (698, 0), (699, 1), (700, 0), (701, 1), (702, 0), (703, 1), (704, 0), (705, 1), (706, 0), (707, 1), (708, 0), (709, 1), (710, 0), (711, 1), (712, 0), (713, 1), (714, 0), (715, 1), (716, 0), (717, 1), (718, 0), (719, 1), (720, 0), (721, 1), (722, 0), (723, 1), (724, 0), (725, 1), (726, 0), (727, 1), (728, 0), (729, 1), (730, 0), (731, 1), (732, 0), (733, 1), (734, 0), (735, 1), (736, 0), (737, 1), (738, 0), (739, 1), (740, 0), (741, 1), (742, 0), (743, 1), (744, 0), (745, 1), (746, 0), (747, 1), (748, 0), (749, 1), (750, 0), (751, 1), (752, 0), (753, 1), (754, 0), (755, 1), (756, 0), (757, 1), (758, 0), (759, 1), (760, 0), (761, 1), (762, 0), (763, 1), (764, 0), (765, 1), (766, 0), (767, 1), (768, 0), (769, 1), (770, 0), (771, 1), (772, 0), (773, 1), (774, 0), (775, 1), (776, 0), (777, 1), (778, 0), (779, 1), (780, 0), (781, 1), (782, 0), (783, 1), (784, 0), (785, 1), (786, 0), (787, 1), (788, 0), (789, 1), (790, 0), (791, 1), (792, 0), (793, 1), (794, 0), (795, 1), (796, 0), (797, 1), (798, 0), (799, 1), (800, 0), (801, 1), (802, 0), (803, 1), (804, 0), (805, 1), (806, 0), (807, 1), (808, 0), (809, 1), (810, 0), (811, 1), (812, 0), (813, 1), (814, 0), (815, 1), (816, 0), (817, 1), (818, 0), (819, 1), (820, 0), (821, 1), (822, 0), (823, 1), (824, 0), (825, 1), (826, 0), (827, 1), (828, 0), (829, 1), (830, 0), (831, 1), (832, 0), (833, 1), (834, 0), (835, 1), (836, 0), (837, 1), (838, 0), (839, 1), (840, 0), (841, 1), (842, 0), (843, 1), (844, 0), (845, 1), (846, 0), (847, 1), (848, 0), (849, 1), (850, 0), (851, 1), (852, 0), (853, 1), (854, 0), (855, 1), (856, 0), (857, 1), (858, 0), (859, 1), (860, 0), (861, 1), (862, 0), (863, 1), (864, 0), (865, 1), (866, 0), (867, 1), (868, 0), (869, 1), (870, 0), (871, 1), (872, 0), (873, 1), (874, 0), (875, 1), (876, 0), (877, 1), (878, 0), (879, 1), (880, 0), (881, 1), (882, 0), (883, 1), (884, 0), (885, 1), (886, 0), (887, 1), (888, 0), (889, 1), (890, 0), (891, 1), (892, 0), (893, 1), (894, 0), (895, 1), (896, 0), (897, 1), (898, 0), (899, 1), (900, 0), (901, 1), (902, 0), (903, 1), (904, 0), (905, 1), (906, 0), (907, 1), (908, 0), (909, 1), (910, 0), (911, 1), (912, 0), (913, 1), (914, 0), (915, 1), (916, 0), (917, 1), (918, 0), (919, 1), (920, 0), (921, 1), (922, 0), (923, 1), (924, 0), (925, 1), (926, 0), (927, 1), (928, 0), (929, 1), (930, 0), (931, 1), (932, 0), (933, 1), (934, 0), (935, 1), (936, 0), (937, 1), (938, 0), (939, 1), (940, 0), (941, 1), (942, 0), (943, 1), (944, 0), (945, 1), (946, 0), (947, 1), (948, 0), (949, 1), (950, 0), (951, 1), (952, 0), (953, 1), (954, 0), (955, 1), (956, 0), (957, 1), (958, 0), (959, 1), (960, 0), (961, 1), (962, 0), (963, 1), (964, 0), (965, 1), (966, 0), (967, 1), (968, 0), (969, 1), (970, 0), (971, 1), (972, 0), (973, 1), (974, 0), (975, 1), (976, 0), (977, 1), (978, 0), (979, 1), (980, 0), (981, 1), (982, 0), (983, 1), (984, 0), (985, 1), (986, 0), (987, 1), (988, 0), (989, 1), (990, 0), (991, 1), (992, 0), (993, 1), (994, 0), (995, 1), (996, 0), (997, 1), (998, 0), (999, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates an RDD from a list of numbers from 0 to 999, then applies the mod function to each number, which returns a tuple containing the number and its remainder when divided by 2. The first 10 of these tuples are then printed."
      ],
      "metadata": {
        "id": "ppdnrr9sYRry"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffpSHVSqoTJG"
      },
      "source": [
        "**Creating an RDD using List**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vny_r0XyoTtX"
      },
      "source": [
        "values = [1, 2, 3, 4, 5]\n",
        "rdd = sc.parallelize(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFiZeKPTojTA"
      },
      "source": [
        "**Printing all the 5 elements of RDD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj2fMbO1ojcP"
      },
      "source": [
        "rdd.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8iceRzJpHEf"
      },
      "source": [
        "**Uploading Files to Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjvkzvVQpHQP"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efk3X18npX8C"
      },
      "source": [
        "**Loading a text file to Spark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msf2fMBIpYCY"
      },
      "source": [
        "rdd = sc.textFile(\"Spark.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzwZVFhWpgWf"
      },
      "source": [
        "**Print the rdd data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRNsJ_Mjpgjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987a916d-0f6f-4420-8ed4-32f44e613b0e"
      },
      "source": [
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"PySpark is the Python API for Apache Spark, an open-source, distributed computing system designed for processing large-scale data across clusters of computers. PySpark allows Python developers to leverage the power of Spark's capabilities for big data processing while using the Python programming language.\",\n",
              " '',\n",
              " 'Key Features of PySpark:',\n",
              " 'Distributed Computing: PySpark enables parallel processing of data across multiple nodes in a cluster, making it possible to handle very large datasets efficiently.',\n",
              " '',\n",
              " 'RDDs (Resilient Distributed Datasets): These are the fundamental data structures in Spark. RDDs represent distributed collections of objects that can be processed in parallel. PySpark provides Python-friendly APIs to work with RDDs.',\n",
              " '',\n",
              " 'DataFrames: Similar to RDDs, DataFrames are distributed collections of data organized into named columns, much like a table in a relational database or a DataFrame in pandas. DataFrames are optimized for performance using Spark’s Catalyst optimizer.',\n",
              " '',\n",
              " 'Machine Learning: PySpark provides the MLlib library, which includes scalable machine learning algorithms for classification, regression, clustering, and collaborative filtering.',\n",
              " '',\n",
              " 'SQL Queries: PySpark allows you to execute SQL queries on DataFrames using Spark SQL, enabling you to interact with data using SQL-like syntax.',\n",
              " '',\n",
              " 'Graph Processing: With PySpark, you can perform graph computations using the GraphX library, which is built on top of Spark.',\n",
              " '',\n",
              " 'Stream Processing: PySpark also supports stream processing through Spark Streaming, which allows you to process real-time data streams.',\n",
              " '',\n",
              " 'Use Cases:',\n",
              " \"Big Data Processing: PySpark is used in scenarios where there are massive datasets that need to be processed and analyzed. It's commonly used in industries like finance, healthcare, and technology.\",\n",
              " 'Data Pipelines: PySpark is often used to build data pipelines that extract, transform, and load (ETL) data from various sources.',\n",
              " 'Machine Learning: With MLlib, PySpark is used for building scalable machine learning models that can handle large datasets.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Iatskrp5Jw"
      },
      "source": [
        "**RDD Persistence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357Jbh7mp5RG",
        "outputId": "c31e6588-18d2-4e9c-ac10-d8aa8d4ef75f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "aba = sc.parallelize(range(1,10000,2))\n",
        "aba.persist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[7] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code creates an RDD called aba that contains all the odd numbers from 1 to 9,999.\n",
        "\n",
        "The persist() method is called on the RDD, which means that Spark will keep the RDD in memory for faster access in future operations.\n",
        "\n",
        "This is useful in scenarios where the RDD aba will be used multiple times, and keeping it in memory avoids the need to recompute or reload the data each time it's accessed."
      ],
      "metadata": {
        "id": "82KvXXvrZ0js"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHcG2CoaqEiS"
      },
      "source": [
        "**RDD Caching**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrWq-IkGqEu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560376fd-9841-41b1-f92e-8fed9de42956"
      },
      "source": [
        "textFile = sc.textFile(\"Spark.txt\")\n",
        "textFile.cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Spark.txt MapPartitionsRDD[9] at textFile at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reads a text file (\"Spark.txt\") into an RDD named textFile, where each element in the RDD represents a line in the file.\n",
        "\n",
        "The cache() method is called on the textFile RDD, instructing Spark to keep the RDD in memory for quicker access during subsequent operations.\n",
        "\n",
        "Caching is beneficial when you know you'll be using the textFile RDD multiple times in your Spark job, as it improves performance by reducing the need to reload or recompute the data."
      ],
      "metadata": {
        "id": "m9kEFWXiaNDL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8DLq1zJrB45"
      },
      "source": [
        "## **Map**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA6UpUBwULjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c014bca-dd73-459d-99f1-9fb877999a75"
      },
      "source": [
        "x = sc.parallelize([\"spark\", \"rdd\", \"example\",  \"sample\", \"example\"])\n",
        "y = x.map(lambda x:(x, 1))\n",
        "y.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark', 1), ('rdd', 1), ('example', 1), ('sample', 1), ('example', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first creates an RDD x from a list of words.\n",
        "\n",
        "It then maps each word to a tuple where the word is paired with the number 1, resulting in RDD y.\n",
        "\n",
        "Finally, collect() retrieves and prints the contents of y.\n",
        "\n",
        "This transformation is commonly used in tasks like word count, where you'd count the occurrences of each word in a dataset. The next step typically involves a reduceByKey() or groupByKey() to aggregate these counts."
      ],
      "metadata": {
        "id": "nJ50w0QCas0V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeGtRS04rHbE"
      },
      "source": [
        "# **FlatMap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdpdIg1SYNQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "7a7cd414-80e9-40fd-8b64-ac14c9a04149"
      },
      "source": [
        "rdd = sc.parallelize([2, 3, 4],numpartition=3)\n",
        "sorted(rdd.flatMap(lambda x: range(1, x)).glom().collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SparkContext.parallelize() got an unexpected keyword argument 'numpartition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-78d0e72f0614>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SparkContext.parallelize() got an unexpected keyword argument 'numpartition'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "flatMap is similar to map, but it flattens the results, meaning that it does not keep the results of each element in separate lists; instead, it merges them into a single list."
      ],
      "metadata": {
        "id": "VTpbqw37bRTc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1ypuSX_rR3m"
      },
      "source": [
        "# **Filter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boh8Bd26Z5j7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721ad71e-1c29-438d-af3d-d5afcb8e73e7"
      },
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6])\n",
        "rdd.filter(lambda x: x % 2 == 0).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first creates an RDD rdd from the list [1, 2, 3, 4, 5, 6].\n",
        "\n",
        "It then applies a filter transformation to keep only the even numbers.\n",
        "collect() retrieves and returns these even numbers as a Python list.\n"
      ],
      "metadata": {
        "id": "IRMkbWMSby3b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzzNRblQrgXX"
      },
      "source": [
        "# **Sample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUtu87OaZ5qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1113d5-d2c8-48ef-e32b-9d69ee81e6bb"
      },
      "source": [
        "parallel = sc.parallelize(range(9))\n",
        "rdd=parallel.sample(True,.2)\n",
        "print(rdd.count())\n",
        "print(rdd.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[4, 5, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first creates an RDD parallel containing numbers from 0 to 8.\n",
        "\n",
        "It then takes a sample from this RDD with replacement, where each element has a 20% chance of being included in the sample.\n",
        "\n",
        "Finally, count() returns the number of elements in this sampled RDD.\n",
        "\n",
        "Output Explanation:\n",
        "\n",
        "The output of the code will be the number of elements in the sampled RDD, which will vary because of the randomness in sampling. Typically, you'd expect around 1-2 elements, but the exact count can differ each time you run the code."
      ],
      "metadata": {
        "id": "LmQNkwCFcHvE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EBw7Qd_cjuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10cb33a8-8037-414c-b26e-5b7776e58ade"
      },
      "source": [
        "parallel.sample(False,0.2).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "False: This indicates that sampling is done without replacement. This means each element can only be selected once in the sampling process.\n",
        "\n",
        "1: This is the sampling fraction. A fraction of 1 means that the sampling process should (in theory) select 100% of the elements. Since the sampling is without replacement, it will simply return all elements of the RDD.\n",
        "\n",
        "Result:\n",
        "\n",
        "Since the fraction is 1 and sampling is without replacement, the entire RDD will be returned in the sample."
      ],
      "metadata": {
        "id": "FfoGA6UpcxH5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2jWTVsosAoO"
      },
      "source": [
        "#**Union**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIAaw0BGcmR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4cf08a-b9b7-49e4-a2f8-6bee656bc012"
      },
      "source": [
        "parallel = sc.parallelize(range(1,9))\n",
        "par = sc.parallelize(range(5,15))\n",
        "parallel.union(par).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code creates two RDDs: parallel containing numbers from 1 to 8, and par containing numbers from 5 to 14.\n",
        "\n",
        "It then takes the union of these two RDDs, resulting in a single RDD containing all the elements from both RDDs.\n",
        "\n",
        "collect() retrieves and returns these elements as a Python list."
      ],
      "metadata": {
        "id": "jPf6M_2VdPpL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3YeIoK-sHrZ"
      },
      "source": [
        "#**Intersection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUk0eTFeBxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b41c62-1dc4-48d3-dcdd-c54059afb81b"
      },
      "source": [
        "parallel = sc.parallelize(range(1,9))\n",
        "par = sc.parallelize(range(5,15))\n",
        "parallel.intersection(par).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 5, 6, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code creates two RDDs: parallel containing numbers from 1 to 8, and par containing numbers from 5 to 14.\n",
        "\n",
        "It then finds the intersection of these two RDDs, resulting in an RDD containing only the elements that are present in both RDDs.\n",
        "\n",
        "collect() retrieves and returns these elements as a Python list."
      ],
      "metadata": {
        "id": "yHduWZSpdh4o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F8TBPjFsPGv"
      },
      "source": [
        "#**Distinct**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMPDLdMfeOtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fdd903-52ae-4245-f052-9a6e154de6bf"
      },
      "source": [
        "parallel = sc.parallelize(range(1,9))\n",
        "par = sc.parallelize(range(5,15))\n",
        "parallel.union(par).distinct().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first creates two RDDs: parallel with numbers from 1 to 8, and par with numbers from 5 to 14.\n",
        "\n",
        "It then performs a union of these two RDDs, which includes all elements from both RDDs, including duplicates.\n",
        "\n",
        "The distinct() transformation removes the duplicate elements, ensuring each number appears only once.\n",
        "\n",
        "Finally, collect() retrieves and returns the unique elements as a Python list."
      ],
      "metadata": {
        "id": "4_o_HFUnd7YN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfR7ygErsU_v"
      },
      "source": [
        "#**SortBy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAyWJFJeeOzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e4484f-9d44-4099-eb7f-951b0e2afe00"
      },
      "source": [
        "y = sc.parallelize([5, 7, 1, 3, 2, 1, 10])\n",
        "y.sortBy(lambda c: c, False).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 7, 5, 3, 2, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code creates an RDD y with the elements [5, 7, 1, 3, 2, 1, 10].\n",
        "\n",
        "It then sorts this RDD in ascending order.\n",
        "\n",
        "collect() retrieves and returns these sorted elements as a Python list."
      ],
      "metadata": {
        "id": "-PhjsvlyeRWw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBAgn2nQeO5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f3bc4d-61ae-4997-dc57-1825747129b8"
      },
      "source": [
        "z = sc.parallelize([(\"H\", 10), (\"A\", 26), (\"Z\", 1), (\"L\", 5)])\n",
        "z.sortBy(lambda c: c, False,).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Z', 1), ('L', 5), ('H', 10), ('A', 26)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = sc.parallelize([(\"H\", 10), (\"A\", 26), (\"Z\", 1), (\"L\", 5)])\n",
        "z.sortBy(lambda c: c[1], False,).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPA6-2v3e_Om",
        "outputId": "02ef3781-94ff-4b9a-9c43-ec4421fc0bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 26), ('H', 10), ('L', 5), ('Z', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code creates an RDD z with the elements [(\"H\", 10), (\"A\", 26), (\"Z\", 1), (\"L\", 5)].\n",
        "\n",
        "It then sorts this RDD in ascending order.\n",
        "\n",
        "collect() retrieves and returns these sorted elements as a Python list."
      ],
      "metadata": {
        "id": "EAhcdfE7e4vZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hhaNbG1sgr3"
      },
      "source": [
        "#**MapPartitions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjWSsNCJeO88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3a075a-a738-478d-a600-14b55f1ad9ff"
      },
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
        "print(rdd.glom().collect())\n",
        "def f(iterator): yield sum(iterator)\n",
        "print(rdd.mapPartitions(f).glom().collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [3, 4]]\n",
            "[[3], [7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RDD rdd is partitioned into two parts: [1, 2] and [3, 4].\n",
        "\n",
        "The function f computes the sum of each partition.\n",
        "mapPartitions applies this function to each partition.\n",
        "collect() retrieves the results.\n"
      ],
      "metadata": {
        "id": "g5Su5Id7fYKD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHh_mtDJsrGP"
      },
      "source": [
        "#**MapPartitions - WithIndex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRFd_BCReO3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98dd96f3-f8cb-4c85-9964-a3a00a546fcb"
      },
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
        "def f(splitIndex, iterator): yield splitIndex\n",
        "rdd.mapPartitionsWithIndex(f).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RDD rdd is partitioned into 4 parts.\n",
        "\n",
        "The function f yields the index of each partition.\n",
        "mapPartitionsWithIndex produces an RDD with partition indices [0, 1, 2, 3].\n",
        "\n",
        "sum() computes the sum of these indices."
      ],
      "metadata": {
        "id": "yyVvbDyVftS7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjwiz2oSs1Ru"
      },
      "source": [
        "#**GroupBy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7aMNjjAeOxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f4f6b9-b49c-45e6-fbf6-2edaf9ffb2d3"
      },
      "source": [
        "rdd = sc.parallelize([1, 1, 2, 3, 5, 8])\n",
        "result = rdd.groupBy(lambda x: x % 2).collect()\n",
        "sorted([(x, sorted(y)) for (x, y) in result],reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, [1, 1, 3, 5]), (0, [2, 8])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code groups the elements of the RDD into even and odd numbers.\n",
        "\n",
        "It sorts the values in each group.\n",
        "\n",
        "It then sorts the groups by the key (0 for even, 1 for odd)."
      ],
      "metadata": {
        "id": "xO6IO311gJrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **cogroup**"
      ],
      "metadata": {
        "id": "vfdR_fQWg1QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sales data RDD: (product_id, sales_amount)\n",
        "sales_data = sc.parallelize([\n",
        "    (1, 100),\n",
        "    (2, 150),\n",
        "    (1, 200),\n",
        "    (3, 300),\n",
        "    (2, 250)\n",
        "])\n",
        "\n",
        "# Product info RDD: (product_id, product_name)\n",
        "product_info = sc.parallelize([\n",
        "    (1, \"Product A\"),\n",
        "    (2, \"Product B\"),\n",
        "    (3, \"Product C\"),\n",
        "    (4, \"Product D\")\n",
        "])\n",
        "# Perform cogroup operation on the two RDDs\n",
        "cogrouped_rdd = sales_data.cogroup(product_info)\n",
        "\n",
        "# Collect and print the result\n",
        "result = cogrouped_rdd.collect()\n",
        "formatted_result = [\n",
        "    (key, (list(value1), list(value2)))\n",
        "    for key, (value1, value2) in result\n",
        "]\n",
        "\n",
        "# Output the formatted result\n",
        "for item in formatted_result:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsn6lztggvXW",
        "outputId": "1d92411c-2d14-4824-b1cc-3c07dea5e976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, ([], ['Product D']))\n",
            "(1, ([100, 200], ['Product A']))\n",
            "(2, ([150, 250], ['Product B']))\n",
            "(3, ([300], ['Product C']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cogrouped_rdd = sales_data.cogroup(product_info)\n",
        "cogrouped_rdd.glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVEfGLIBIItv",
        "outputId": "627c5738-2b55-46b2-a0e3-f2387e6bef5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(4,\n",
              "   (<pyspark.resultiterable.ResultIterable at 0x7a996c06baf0>,\n",
              "    <pyspark.resultiterable.ResultIterable at 0x7a996c06aec0>))],\n",
              " [(1,\n",
              "   (<pyspark.resultiterable.ResultIterable at 0x7a995c2a2fb0>,\n",
              "    <pyspark.resultiterable.ResultIterable at 0x7a995c2a3c10>))],\n",
              " [(2,\n",
              "   (<pyspark.resultiterable.ResultIterable at 0x7a995c2a0e20>,\n",
              "    <pyspark.resultiterable.ResultIterable at 0x7a995c2a0130>))],\n",
              " [(3,\n",
              "   (<pyspark.resultiterable.ResultIterable at 0x7a995c2a2320>,\n",
              "    <pyspark.resultiterable.ResultIterable at 0x7a995c2a3a60>))]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sales_data RDD has keys 1, 2, and 3 with sales amounts.\n",
        "product_info RDD has keys 1, 2, 3, and 4 with product names.\n",
        "cogroup groups the data by product ID, so each key will have two lists:\n",
        "\n",
        "One list with sales amounts (from sales_data).\n",
        "\n",
        "One list with product names (from product_info)."
      ],
      "metadata": {
        "id": "WYQfMRXmh_C5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEvq3648s8aC"
      },
      "source": [
        "#**KeyBy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr4gQBDYmtEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffce1d8-5ba5-455f-c10b-558262950aaa"
      },
      "source": [
        "x = sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
        "y = sc.parallelize(zip(range(0,5), range(0,5)))\n",
        "[(x, list(map(list, y))) for x, y in sorted(x.cogroup(y).collect())]\n",
        "x.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0), (1, 1), (4, 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code creates two RDDs: x with keys based on squared values and y with key-value pairs.\n",
        "\n",
        "It performs a cogroup operation to group these RDDs by key.\n",
        "\n",
        "The result is collected and sorted, converting the grouped values into lists for easier readability."
      ],
      "metadata": {
        "id": "V12vc_SvgoTC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJkk3z0JtCKn"
      },
      "source": [
        "#**Zip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjfG4WOUm75-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bdb76e-7795-4ad4-e2a4-d45bbac4e65c"
      },
      "source": [
        "x = sc.parallelize(range(0,5))\n",
        "y = sc.parallelize(range(1000, 1005))\n",
        "x.zip(y).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The zip operation combines the two RDDs into tuples based on the position of the elements.\n",
        "\n",
        "The collect() action retrieves the combined result as a list of tuples."
      ],
      "metadata": {
        "id": "axaUA_XMiXjY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg6ntoZHtJ6B"
      },
      "source": [
        "#**Zip - WithIndex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxBqVMuxzoNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa274db-36e1-4025-8d1a-2a7ecffeeae5"
      },
      "source": [
        "sc.parallelize([\"a\", \"b\", \"c\", \"d\"], 5).zipWithIndex().glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [('a', 0)], [('b', 1)], [('c', 2)], [('d', 3)]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.parallelize([\"a\", \"b\", \"c\", \"d\"], 2).zipWithIndex().glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3bMiGzBi6Of",
        "outputId": "f26f52f3-ad74-4d5f-a032-cb033dadb944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('a', 0), ('b', 1)], [('c', 2), ('d', 3)]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This transformation pairs each element of the RDD with its index, starting from 0.\n",
        "It produces an RDD of tuples where each tuple consists of an element from the original RDD and its corresponding index."
      ],
      "metadata": {
        "id": "N5Wq2yaginmB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXL-J06QtRXm"
      },
      "source": [
        "#**Repartition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133AwSCM0zqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b45a223-d1fb-4577-de1a-4357736e63ed"
      },
      "source": [
        "rdd = sc.parallelize([1,2,3,4,5,6,7], 4)\n",
        "sorted(rdd.glom().collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1], [2, 3], [4, 5], [6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf87x1_V1XTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6c0c74-b119-46a4-e65c-6b8f806f971b"
      },
      "source": [
        "rdd.repartition(2).glom().collect()\n",
        "#len(rdd.repartition(2).glom().collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 5, 6, 7], [1, 2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The repartition(2) transformation reshuffles the RDD to have 2 partitions. This operation might involve data shuffling."
      ],
      "metadata": {
        "id": "ulETWY14jjOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sorted(rdd.glom().collect()) will show the partitioned RDD as a sorted list of lists.\n",
        "\n",
        "len(rdd.repartition(2).glom().collect()) will return the number of partitions after repartitioning, which is 2 in this case."
      ],
      "metadata": {
        "id": "7NkdiRSsjZuD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zuIxa7Wte9m"
      },
      "source": [
        "#**Coalesce**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHwhvUe71XZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b29aa4-a62b-483a-f142-005444b68de5"
      },
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5,6,7], 4).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1], [2, 3], [4, 5], [6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_9XK651Xbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccbfe86-b4e7-42a3-9930-b1445187cf22"
      },
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5,6,7], 4).coalesce(2).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3], [4, 5, 6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "coalesce(n) is used to reduce the number of partitions from the current number to n.\n",
        "\n",
        "Unlike repartition, coalesce tries to minimize data movement and is more efficient for reducing the number of partitions.\n"
      ],
      "metadata": {
        "id": "Iv5_DO6Bj-fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Action**"
      ],
      "metadata": {
        "id": "Zh-fu1EIkQ4T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_JIusPJttPy"
      },
      "source": [
        "# **Reduce**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKvSQzLM1Xhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1945692-824d-4797-e744-1dd063e4e8d4"
      },
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5]).map(lambda x:(1,x)).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5]) creates an RDD from the list.\n",
        "\n",
        ".reduce(lambda x, y: x + y) computes the sum of all elements in the RDD."
      ],
      "metadata": {
        "id": "2I-G-qUPks9o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAYW0kVtt0zP"
      },
      "source": [
        "#**First**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNMtXMro6txZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcf2278-9273-46c4-9c3b-25e4d87870f1"
      },
      "source": [
        "sc.parallelize([1, 2, 3, 4]).first()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 2, 3, 4]) creates an RDD from the list.\n",
        "\n",
        ".first() retrieves the first element of the RDD."
      ],
      "metadata": {
        "id": "_xxC0WVQk4ym"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXwTEmBNt5G2"
      },
      "source": [
        "#**TakeOrdered**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xPONGoU6t1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c0cc5f-8613-4400-db30-a5bdf4e74996"
      },
      "source": [
        "nums = sc.parallelize([1,5,3,9,4,0,2])\n",
        "nums.takeOrdered(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 5, 3, 9, 4, 0, 2]) creates an RDD from the list.\n",
        "\n",
        ".takeOrdered(5) retrieves the 5 smallest elements from the RDD in ascending order.\n"
      ],
      "metadata": {
        "id": "-xuKOjeTlEGs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_tYE0vft_Ah"
      },
      "source": [
        "#**Take**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a06dpPPf8qPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d71c567-c246-4010-e18c-bce909b7a952"
      },
      "source": [
        "nums = sc.parallelize([1,5,3,9,4,0,2])\n",
        "nums.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 5, 3, 9, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 5, 3, 9, 4, 0, 2]) creates an RDD from the list.\n",
        "\n",
        ".take(5) retrieves the first 5 elements from the RDD as a list."
      ],
      "metadata": {
        "id": "DBQyn70ylP8H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1j5GKIuuD_f"
      },
      "source": [
        "#**Count**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQxi9W4s9JRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d7f4ab-c193-46e1-d280-43279a8b368a"
      },
      "source": [
        "nums = sc.parallelize([1,5,3,9,4,0,2,4])\n",
        "nums.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 5, 3, 9, 4, 0, 2, 4]) creates an RDD from the list.\n",
        "\n",
        ".count() returns the total number of elements in the RDD."
      ],
      "metadata": {
        "id": "M6hY_qPqlZ7L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjm4TOmXuIJG"
      },
      "source": [
        "#**Collect**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGm84WiJ9p8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4327558-3317-4110-87df-ae976fbe3073"
      },
      "source": [
        "c = sc.parallelize([\"Gnu\", \"Cat\", \"Rat\", \"Dog\", \"Gnu\", \"Rat\"], 2)\n",
        "c.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gnu', 'Cat', 'Rat', 'Dog', 'Gnu', 'Rat']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This action retrieves all the elements from the RDD and returns them as a list.\n",
        "\n",
        "It combines the elements from all partitions and returns them in a list, although the order might not be guaranteed due to the distributed nature of the RDD."
      ],
      "metadata": {
        "id": "IAHv48Vtl2Fy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvVKrtdb-VvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef20b828-e616-44cc-9c08-a8ade4a02701"
      },
      "source": [
        "c = sc.parallelize([\"Gnu\", \"Cat\", \"Rat\", \"Dog\", \"Gnu\", \"Rat\"], 2)\n",
        "c.distinct().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cat', 'Rat', 'Gnu', 'Dog']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PdtEWDuNcq"
      },
      "source": [
        "# **CollectAsMap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV_k5oVo-VyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378a04c8-5913-4b77-b739-ed2a3bf6c6c2"
      },
      "source": [
        "alphanumerics = sc.parallelize([(1,\"a\"),(2,\"b\"),(3,\"c\"),(1,\"b\")])\n",
        "alphanumerics.collectAsMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'b', 2: 'b', 3: 'c'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([(1, \"a\"), (2, \"b\"), (3, \"c\")]) creates an RDD of key-value pairs.\n",
        "\n",
        ".collectAsMap() converts the RDD into a dictionary."
      ],
      "metadata": {
        "id": "i6z4qr1NmHv-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eLYjrcauYsu"
      },
      "source": [
        "#**SaveAsTextfile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryfna99q-V1Z"
      },
      "source": [
        "a = sc.parallelize(range(1,10000), 3)\n",
        "a.saveAsTextFile(\"/content/mydata_a1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PuKgIRE-V4q"
      },
      "source": [
        "x = sc.parallelize([1,2,3,4,5,6,6,7,9,8,10,21], 3)\n",
        "x.saveAsTextFile(\"/usr/bin/sample1.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5, 6, 6, 7, 9, 8, 10, 21], 3) creates an RDD with 3 partitions.\n",
        "\n",
        ".saveAsTextFile(\"/usr/bin/sample1.txt\") saves the RDD to the specified directory in text format, with each partition written to a separate file."
      ],
      "metadata": {
        "id": "L5ZruVmIma12"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaW50nRZuh0X"
      },
      "source": [
        "#**Foreach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgfnEsb_-V7q"
      },
      "source": [
        "def f(x): print(x)\n",
        "sc.parallelize([1,2,3,4,5]).foreach(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def f(x): print(x) defines a function that prints each element.\n",
        "\n",
        "sc.parallelize([1, 2, 3, 4, 5]).foreach(f) applies the function f to each element in the RDD, printing each element to the console."
      ],
      "metadata": {
        "id": "ItHF9R2mmqnv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0YQtfvMuoh2"
      },
      "source": [
        "#**Foreach - Partition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruP1JW0-DHF5"
      },
      "source": [
        "def f(iterator):\n",
        "  for x in iterator:\n",
        "    print(x)\n",
        "sc.parallelize([1, 2, 3, 4, 5]).foreachPartition(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "foreachPartition passes an iterator of the elements of each partition to the function f.\n",
        "\n",
        "The function f then iterates over this iterator and prints each element of the partition."
      ],
      "metadata": {
        "id": "mU6J9L2CnJpK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COMyaOJ8uvB-"
      },
      "source": [
        "#**Mathematical Actions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpPIG1XJ47i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242aae4b-a6f1-43bf-96cb-4859108a1d64"
      },
      "source": [
        "numbers = sc.parallelize(range(1,100))\n",
        "numbers.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orlQdpAPKglG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5e89f5-7886-424e-c0e6-af56d8364279"
      },
      "source": [
        "numbers.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4950"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neMtlNsLKgoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8461d905-85af-431e-fa29-aafd362c2104"
      },
      "source": [
        "numbers.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr1FdY33KgrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818488f7-b8bc-4cfd-b4fb-c9c12dec55e2"
      },
      "source": [
        "numbers.variance()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "816.6666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOjdpMoiKgt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd9577e-2840-4b30-b6ca-17011e90ca3f"
      },
      "source": [
        "numbers.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOzATfpJKgw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bba1681-cadf-449b-ede8-647f56413f0d"
      },
      "source": [
        "numbers.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dadfjRqiKgzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6738ebe-ee1f-4a32-bbbb-22427856d186"
      },
      "source": [
        "numbers.stdev()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.577380332470412"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyi9_Y9Su5K0"
      },
      "source": [
        "#**CountByValue**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7bhmrxZKg2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac3830-634e-4652-c588-f4a339700951"
      },
      "source": [
        "a = sc.parallelize([1,2,3,4,5,6,7,8,2,4,2,3,3,3,1,1,1])\n",
        "a.countByValue()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {1: 4, 2: 3, 3: 4, 4: 2, 5: 1, 6: 1, 7: 1, 8: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 2, 3, 3, 3, 1, 1, 1]) creates an RDD from the list.\n",
        "\n",
        ".countByValue() returns a dictionary with counts of each unique value in the RDD."
      ],
      "metadata": {
        "id": "--4Ory0dnil_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRq8fRf_vBjP"
      },
      "source": [
        "#**toDebugString**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z68rnsbKg51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9abac7-256c-403f-e62b-13b3cd379862"
      },
      "source": [
        "a = sc.parallelize(range(1,19),3)\n",
        "b = sc.parallelize(range(1,13),3)\n",
        "c = a.subtract(b)\n",
        "c.toDebugString()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'(6) PythonRDD[175] at RDD at PythonRDD.scala:53 []\\n |  MapPartitionsRDD[174] at mapPartitions at PythonRDD.scala:160 []\\n |  ShuffledRDD[173] at partitionBy at NativeMethodAccessorImpl.java:0 []\\n +-(6) PairwiseRDD[172] at subtract at <ipython-input-54-e1f9a4054d92>:3 []\\n    |  PythonRDD[171] at subtract at <ipython-input-54-e1f9a4054d92>:3 []\\n    |  UnionRDD[170] at union at NativeMethodAccessorImpl.java:0 []\\n    |  PythonRDD[168] at RDD at PythonRDD.scala:53 []\\n    |  ParallelCollectionRDD[166] at readRDDFromFile at PythonRDD.scala:289 []\\n    |  PythonRDD[169] at RDD at PythonRDD.scala:53 []\\n    |  ParallelCollectionRDD[167] at readRDDFromFile at PythonRDD.scala:289 []'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize(range(1, 19), 3) creates RDD a with values [1, 2, ..., 18] in 3 partitions.\n",
        "\n",
        "sc.parallelize(range(1, 13), 3) creates RDD b with values [1, 2, ..., 12] in 3 partitions.\n",
        "\n",
        "a.subtract(b) computes the difference, resulting in RDD c with values [13, 14, 15, 16, 17, 18].\n",
        "\n",
        "c.toDebugString() provides a detailed string representation of RDD c’s lineage and partitioning."
      ],
      "metadata": {
        "id": "AZsfdjfZnzWh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-BEEQC09z1"
      },
      "source": [
        "#**Creating Pair RDDs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSRaEJrg09-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f816431-7628-462d-b442-198f053ea0e4"
      },
      "source": [
        "rdd = sc.parallelize([(\"a1\", \"b1\", \"c1\", \"d1\", \"e1\"), (\"a2\", \"b2\", \"c2\", \"d2\", \"e2\")])\n",
        "result = rdd.map(lambda x: (x[0], list(x[1:])))\n",
        "result.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a1', ['b1', 'c1', 'd1', 'e1']), ('a2', ['b2', 'c2', 'd2', 'e2'])]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.parallelize([(\"a1\", \"b1\", \"c1\", \"d1\", \"e1\"), (\"a2\", \"b2\", \"c2\", \"d2\", \"e2\")]) creates an RDD of tuples.\n",
        "\n",
        "rdd.map(lambda x: (x[0], list(x[1:]))) transforms each tuple into a tuple where the first element is kept, and the remaining elements are turned into a list.\n",
        "\n",
        "result.collect() retrieves the transformed tuples from the RDD.\n"
      ],
      "metadata": {
        "id": "qsO6g05noRRu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-iU_1eT12x8"
      },
      "source": [
        "#**WordCount using RDD concepts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShjnA8gyKg9K"
      },
      "source": [
        "rdd =sc.textFile(\"Spark.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQGRiDf9bHKY"
      },
      "source": [
        "nonempty_lines = rdd.filter(lambda x: len(x) > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sc.textFile(\"Spark.txt\"):\n",
        "\n",
        "Reads the text file \"Spark.txt\" into an RDD where each element is a line from the file.\n",
        "rdd.filter(lambda x: len(x) > 0):"
      ],
      "metadata": {
        "id": "Ro97on8spUNW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9KXKm8qbHNv"
      },
      "source": [
        "words = nonempty_lines.flatMap(lambda x: x.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filters out any empty lines from the RDD. The lambda function lambda x: len(x) > 0 checks if the length of the line is greater than 0. nonempty_lines.flatMap(lambda x: x.split(' ')):\n",
        "\n",
        "Splits each line into words. flatMap is used to flatten the resulting lists of words into a single RDD of words.\n",
        "The lambda function lambda x: x.split(' ') splits each line by spaces."
      ],
      "metadata": {
        "id": "35gLKtL0pbsP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL6vGIigbHRA"
      },
      "source": [
        "wordcount = words.map(lambda x:(x,1)).reduceByKey(lambda x,y: x+y).map(lambda x: (x[1], x[0])).sortByKey(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "words.map(lambda x: (x, 1)):\n",
        "\n",
        "Maps each word to a key-value pair where the key is the word and the value is 1.\n",
        "This prepares the RDD for counting occurrences.\n",
        "reduceByKey(lambda x, y: x + y):\n",
        "\n",
        "Reduces the key-value pairs by key, summing up the values.\n",
        "This counts the occurrences of each word.\n",
        "map(lambda x: (x[1], x[0])):\n",
        "\n",
        "Maps the (word, count) pairs to (count, word) pairs to facilitate sorting by count.\n",
        "This prepares the data for sorting by frequency.\n",
        "sortByKey(False):\n",
        "\n",
        "Sorts the RDD by the count in descending order (largest count first).\n",
        "wordcount.take(10):"
      ],
      "metadata": {
        "id": "LPM4Uzcvpxfy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OThqEqgGbHVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb000f8-8f47-4d1c-9c2d-b0c9b604d460"
      },
      "source": [
        "for word in wordcount.take(10):\n",
        "   print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 'PySpark')\n",
            "(9, 'data')\n",
            "(9, 'to')\n",
            "(7, 'of')\n",
            "(7, 'in')\n",
            "(6, 'the')\n",
            "(6, 'for')\n",
            "(5, 'is')\n",
            "(5, 'using')\n",
            "(4, 'are')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In2bZwnUbHZY"
      },
      "source": [
        "wordcount.saveAsTextFile(\"/content/Wordcount\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Takes the top 10 most frequent words (by count) from the RDD.\n",
        "for word in wordcount.take(10): print(word):\n",
        "\n",
        "Prints each of the top 10 most frequent words and their counts.\n",
        "wordcount.saveAsTextFile(\"/content/Wordcount\"):\n",
        "\n",
        "Saves the word count results to the directory /content/Wordcount.\n",
        "Each file in the directory will contain part of the result, with the counts and words."
      ],
      "metadata": {
        "id": "cBFUFeigpGnR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C457y7JJpIiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}